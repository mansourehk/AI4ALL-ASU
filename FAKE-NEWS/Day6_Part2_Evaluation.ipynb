{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='SEAGREEN'>Day 6 (Part 2)</font>\n",
    "# <font color='MEDIUMSEAGREEN'>Evaluation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, to evaluate our methods we used scikit's learn ``accuracy_score`` function.\n",
    "In this session we will learn how we can calculate the metrics ourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "\n",
    "Consider the following table,\n",
    "\n",
    "| $n=165$ | Predicted: No   | Predicted: Yes\n",
    "|------|------|------|\n",
    "|   Actual: No  | $50$ | $10$\n",
    "|   Actual: Yes  | $5$ | $100$\n",
    "\n",
    "What can we learn from this matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many possible predicted classes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we were predicting the presence of a disease, for example, \"yes\" would mean they have the disease, and \"no\" would mean they don't have the disease.\n",
    "\n",
    "The classifier made a total of 165 predictions (e.g., 165 patients were being tested for the presence of that disease)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Out of those 165 cases, how many times the classifier predicted \"yes\"? How many no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, how many patients do have a disease and how many do not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Terms\n",
    "- **true positives (TP):** These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "- **true negatives (TN):** We predicted no, and they don't have the disease.\n",
    "- **false positives (FP):** We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "- **false negatives (FN):** We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down which cell of the above table is related to each of the terms (e.g. 50 is AB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a list of rates that are often computed from a confusion matrix for a binary classifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy: Overall, how often is the classifier correct?\n",
    "$$\\frac{(TP+TN)}{total}$$\n",
    "\n",
    "\n",
    "- Misclassification Rate: Overall, how often is it wrong?\n",
    "$$\\frac{(FP+FN)}{total}$$ \n",
    "    equivalent to 1 minus Accuracy.\n",
    "    \n",
    "    also known as \"Error Rate\"\n",
    "    \n",
    "    \n",
    "- True Positive Rate: When it's actually yes, how often does it predict yes?\n",
    "$$\\frac{TP}{Actual Yes}$$ \n",
    "    also known as \"Sensitivity\" or \"Recall\"\n",
    "    \n",
    "    \n",
    "- False Positive Rate: When it's actually no, how often does it predict yes?\n",
    "$$\\frac{FP}{Actual No}$$ \n",
    "\n",
    "\n",
    "- True Negative Rate: When it's actually no, how often does it predict no?\n",
    "$$\\frac{TN}{Actual No}$$ \n",
    "    equivalent to 1 minus False Positive Rate\n",
    "    \n",
    "    also known as \"Specificity\"\n",
    "    \n",
    "    \n",
    "- Precision: When it predicts yes, how often is it correct?\n",
    "$$\\frac{TP}{Predicted Yes}$$ \n",
    "\n",
    " \n",
    "- Prevalence: How often does the yes condition actually occur in our sample?\n",
    "$$\\frac{Actual Yes}{Total}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate all the above metrics with the given example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Time\n",
    "1. Learn about F1-Score and ROC curve. \n",
    "2. Calculate the F1-Score for the above example. \n",
    "3. Learn how to code and plot the ROC curve.\n",
    "4. Plot the ROC curve for the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score:\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the following functions:\n",
    "\n",
    "1. A function named ``true_positive``.\n",
    "2. A function named ``false_positive``.\n",
    "3. A function named ``true_negative``.\n",
    "4. A function named ``false_negative``.\n",
    "    \n",
    "    Inputs for the functions will be: ``y_pred`` (a list that contains the predicted labels) and ``y_true`` (a list that contains the actual labels for the instances).\n",
    "\n",
    "Also define the following functions with proper inputs based on their formula.\n",
    "1. ``precision_score``\n",
    "2. ``recall score``\n",
    "3. ``f1_score``\n",
    "4. ``accuracy_score``\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the Best Classifier\n",
    "### Load the data\n",
    "Use your improved data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to test and training set\n",
    "Set the random state value to 42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier\n",
    "Copy your code from the previous notebooks to fit a KNN classifier to your data. Use a for loop to test different k values from 1 to 10 and use a plot showing the value of each metric corresponding to each k. Then save Accuracy, Precision, Recall, and F1 score of the best k in ``acc_knn``, ``p_knn``, ``r_knn``, and ``f1_knn`` using your defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes Classifier\n",
    "Read about Gaussian Naive Bayes (NB) [here](https://scikit-learn.org/stable/modules/naive_bayes.html). Then, write a piece of code to fit a Gaussian NB classifier to data and print Accuracy, Precision, Recall, and F1 score. Save the scores in ``acc_gnb``, ``p_gnb``, ``r_gnb``, and ``f1_gnb``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Classifier\n",
    "We already learned about Multinomial Naive Bayes in previous sessions. Copy your code from the previous notebooks to fit a Multinomial Naive Bayes to your data. Print Accuracy, Precision, Recall, and F1 score. Save the scores in ``acc_mnb``, ``p_mnb``, ``r_mnb``, and ``f1_mnb``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Read about Decision Trees (DT) [here](https://scikit-learn.org/stable/modules/tree.html). Then, write a piece of code to fit a DT classifier to your data and print Accuracy, Precision, Recall, and F1 score. \n",
    "\n",
    "#### Parameter Tuning\n",
    "Change maximum depth in your decision tree and observe its effect on the metrics. Try at least 10 different values and generate a plot showing the value of each metric corresponding to each depth.\n",
    "\n",
    "Save the scores of the best one in ``acc_dt``, ``p_dt``, ``r_dt``, and ``f1_dt``.\n",
    "\n",
    "Recall: we also learned about the decision trees in practice problems throughout the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "Copy your SVM code from previous notbooks. SVM is one the strongest and most popular classifiers in the field of Data Science. Write a piece of code that fits an SVM classifier to your data.\n",
    "#### Parameter Tuning\n",
    "Retrain your SVM classifier with different kernels and save the metrics of the best one in ``acc_svm``, ``p_svm``,`` r_svm``, ``f1_svm``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best model\n",
    "Generate 4 plots, each for comparing the classifiers based on one metirc. The x axis will be the models and the y axis will be the value of the corresponding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the aforementioned steps for the data without stemming/lemmatization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GBN\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNB\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to choose the best model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Exercises (optional)**:\n",
    "1. Use different test and train ratios (10/90, 20/80, 30/70).\n",
    "2. Learn about cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We are almost done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
