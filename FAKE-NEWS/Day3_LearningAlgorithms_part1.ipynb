{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='SEAGREEN'>Day 3</font>\n",
    "# <font color='MEDIUMSEAGREEN'>Learning Algorithms</font>\n",
    "### <font color='MEDIUMSEAGREEN'>Part 1</font>\n",
    "\n",
    "There are three major types of machine learning algorithms:\n",
    "1. **Supervised Learning:** a type of machine learning where we are given data as an input and attempt to output the correct label. In other words, we are looking for learning patterns from labeled data and classify new data with labels. \n",
    "    \n",
    "    Examples:\n",
    "    - Classify a Twitter user a “bot” or “human”.\n",
    "    - Classify an e-mail as \"legitimate\" or \"spam\".\n",
    "    - Decide based on the weather, if we should play golf or not.\n",
    "    \n",
    "    There are two types of tasks in supervised learning:\n",
    "    1. Classification: When the label is a specific class (you can label data from discrete finite set of numbers).\n",
    "    2. Regression: When the label is a real number.\n",
    "    \n",
    "2. **Unsupervised Learning:** a type of machine learning where we attempt to make inferences about unlabelled data. Clustering is a form of unsupervised learning which group together similar items.\n",
    "\n",
    "3. **Reinforcement Learning:** a type of machine learning that is about taking suitable action to maximize reward in a particular situation.\n",
    "\n",
    "Based on the data we have, which learning algorithm do you think it is better to use? and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nearest Neighbor Classifier\n",
    "As the name suggests, k-nearest neighbor or k-NN uses the k nearest instances, called neighbors, to perform classification. The instance being classified is assigned the label (class attribute value) that the majority of its k neighbors are assigned.\n",
    "\n",
    "When k = 1, the closest neighbor’s label is used as the predicted label for the instance being classified. To determine the neighbors of an instance, we need to measure its distance to all other instances based on some distance metric. Commonly, Euclidean distance is employed; however, for higher dimensional spaces, Euclidean distance becomes less meaningful\n",
    "and other distance measures can be used.\n",
    "\n",
    "**Example 1**: Consider the example depicted in the following image.\n",
    "<img src=\"images/knn.png\">\n",
    "What would be the label of the circle instance if we consider 5-nn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What would be the label of the circle instance if we consider 10-nn?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Answer: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the above example, an important issue with the k-nearest neighbor algorithm is the choice of k. The choice of k can easily change the label of the instance being predicted. In general, we are interested in a value of k that maximizes the performance of the learning algorithm.\n",
    "\n",
    "### Euclidean Distance\n",
    "As stated, to measure the similarity between two instances we can use Euclidean distance.\n",
    "Suppose that P is a point in x-y plane (2-dimensional plane) with $(x_p, y_p)$ and Q is another point with $(x_q, y_q)$. The euclidean distance can be calculated as:\n",
    "\n",
    "$$d = \\sqrt{(x_p-x_q)^2+(y_p-y_q)^2}$$\n",
    "\n",
    "<img src=\"images/euclid.png\">\n",
    "\n",
    "What would be the Euclidean distance of two points $(x_p, y_p, z_p)$ and $(x_q, y_q, z_q)$ in 3D plane?\n",
    "\n",
    "*Show your answer to the instructor.*\n",
    "\n",
    "**Exersice:** There is another distance named Manhattan distance (or $l_1$ norm). Search and find out how we can calculate this distance. Write down the Manhattan distance for points P and Q in 2-D space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to implement k-nn algorithm.\n",
    "\n",
    "We start with writing a simple sample then we will work on our fake news dataset.\n",
    "\n",
    "Consider the following graphical example with three classes of objects represented as 2D points colored by class. In this case, and for nearest neighbors in general, we consider \"most similar\" to mean \"closest,\". If you wanted to predict the class of the black stars using the closest point (1-nearest neighbor), what would be the predictions? How about if you used the 5 closest points (5-nearest neighbors)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your guess for using 1-nearest neighbor for right star:\n",
    "# Your guess for using 1-nearest neighbor for left star:\n",
    "# Your guess for using 5-nearest neighbor for right star:\n",
    "# Your guess for using 5-nearest neighbor for left star:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "# lists of points\n",
    "points = np.array([(1, 8), (2.4, 5), (3,6), (2,4), (1.8, 7), (3, 3.7), (1, 5.5),\n",
    "                   (7,8), (9, 6), (10, 9), (6,10), (8,11), (8.2,9.5),\n",
    "                   (5,1), (6, 3), (6, 5.7), (4.5,5), (5.5,3.5), (6.7, 2), (3,4.2)])\n",
    "\n",
    "classes = np.array([0, 0, 0, 0, 0, 0, 0, \n",
    "                    1, 1, 1, 1, 1, 1, \n",
    "                    2, 2, 2, 2, 2, 2, 2])\n",
    "\n",
    "unknown = np.array([(3, 4.7), (8,8)])\n",
    "\n",
    "# plotting\n",
    "colors = ['red','green','blue']\n",
    "plt.scatter(*zip(*points), c=classes, cmap=mpl.colors.ListedColormap(colors))\n",
    "plt.plot(*zip(*unknown), '*', color='black', markersize=10)\n",
    "plt.xlim((-1,11))\n",
    "plt.ylim((-1,12))\n",
    "plt.grid(linestyle='--', alpha=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GOOD NEWS: python have a built-in function for nearest neighbor algorithm.\n",
    "\n",
    "Let's try using the python Nearest Neighbors function with the above example points.\n",
    "\n",
    "Run the following cell with different values of $k$ to verify your guess from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Create a nearest neighbors object\n",
    "k = ??\n",
    "nn = KNeighborsClassifier(n_neighbors=k)\n",
    "\n",
    "\n",
    "nn.fit(points, classes)\n",
    "\n",
    "\n",
    "predictions = nn.predict(unknown)\n",
    "\n",
    "# print the predictions\n",
    "print([colors[i] for i in predictions])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do you think the ``.fit()`` and ``.predict`` functions do for KNeighborsClassifier? (You can google the answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data (``X.csv``) and save it to ``X``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the labels (``labels.csv``) and save it to ``y``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's divide the articles into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# the 'test_size' parameter determines what fraction of the data is reserved for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do you think we need to have two different sets for training and test phase?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the classifier on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the labels for the test set points using the trained classifier and compare the predicted labels to the actual labels. Refer to the [accuracy_score documentation](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html) to learn which arguments should be passed to 'accuracy_score()'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete the code\n",
    "from sklearn.metrics import accuracy_score\n",
    "# predict the value of the test set points. \n",
    "labels_predictions = knn.predict(??)\n",
    "\n",
    "# calculate the accuracy\n",
    "accuracy = accuracy_score(??,  ??)\n",
    "\n",
    "# print the accuracy\n",
    "print(??)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try different values for k.\n",
    "\n",
    "Which value gives you the best accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is suggested that it is better to pick odd number for the k value.\n",
    "\n",
    "Find out why and write your answer in the following block."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Exercise:** In previous tutorials you learned how to illustrate a scatter plot. \n",
    "\n",
    "Use a for loop that iterates on k in range 1 to 10, and trains the knn and saves the accuracy in a list.\n",
    "\n",
    "Finally, demonstrate the (k-accuracy)-plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**: The default distance metric used in ``KNeighborsClassifier`` is Euclidean. Search how you can change it to Manhattan distance.\n",
    "Train your data with k-NN algorithm that uses Manhattan distance. Compare the calculated accuracy with the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Exercise:** *implementing k-NN from scratch*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following instructions to implement k-NN from scratch:\n",
    "1. Split the data to test and training set.\n",
    "2. Set a value for k.\n",
    "3. For each sample in test set, by utilizing the Euclidean distance, find the similarity between that test sample with all training examples.\n",
    "4. Pick k training examples with minimum distance.\n",
    "5. Check their labels and find the label of the majority of the examples (majority vote).\n",
    "6. Assign that label to the test example.\n",
    "7. Append the label to y_pred list that saves all the calculated labels for test samples\n",
    "8. Repeat steps 3-7 for all test examples.\n",
    "9. Compare the calculated results with the true labels.\n",
    "10. Report the accuracy.\n",
    "11. Use ``time`` library and calculate the running time of your program. Also, calculate the running time of ``KNeighborsClassifier`` classifier in scikit learn. Report which one runs faster and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code\n",
    "\n",
    "\n",
    "\n",
    "# Running time of your code:\n",
    "# Running time of KNeighborsClassifier:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Exercise:** In previous lessons, you learned how to use scikit learn's decision tree. Implement that algorithm on your data. Try different parameters (e.g. max_depth) and find the best accuracy.\n",
    "\n",
    "More information on Scikit learn's documentation: https://scikit-learn.org/stable/modules/tree.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Good job, as always!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "    - Zafarani, Reza, Mohammad Ali Abbasi, and Huan Liu. Social media mining: an introduction. Cambridge University Press, 2014.\n",
    "    - AI4ALL Slides by Wells Lucas Santo\n",
    "    - Princeton AI4ALL IoT Project"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
