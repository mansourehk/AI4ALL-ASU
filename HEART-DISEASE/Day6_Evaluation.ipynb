{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='SEAGREEN'>Day 6</font>\n",
    "# <font color='MEDIUMSEAGREEN'>Evaluation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far, to evaluate our methods we used scikit's learn ``accuracy_score`` function.\n",
    "In this session we will learn how we can calculate the metrics ourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A confusion matrix is a table that is often used to describe the performance of a classification model (or \"classifier\") on a set of test data for which the true values are known.\n",
    "\n",
    "Consider the following table,\n",
    "\n",
    "| $n=165$ | Predicted: No   | Predicted: Yes\n",
    "|------|------|------|\n",
    "|   Actual: No  | $50$ | $10$\n",
    "|   Actual: Yes  | $5$ | $100$\n",
    "\n",
    "What can we learn from this matrix?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many possible predicted classes are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose, we were predicting the presence of a disease, for example, \"yes\" would mean they have the disease, and \"no\" would mean they don't have the disease.\n",
    "\n",
    "The classifier made a total of 165 predictions (e.g., 165 patients were being tested for the presence of that disease).\n",
    "\n",
    "Out of those 165 cases, how many times the classifier predicted \"yes\"? How many no?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, how many patients do have a disease and how many do not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Terms\n",
    "- **true positives (TP):** These are cases in which we predicted yes (they have the disease), and they do have the disease.\n",
    "- **true negatives (TN):** We predicted no, and they don't have the disease.\n",
    "- **false positives (FP):** We predicted yes, but they don't actually have the disease. (Also known as a \"Type I error.\")\n",
    "- **false negatives (FN):** We predicted no, but they actually do have the disease. (Also known as a \"Type II error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write down which cell of the above table is related to each of the terms (e.g. 50 is AB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Accuracy: Overall, how often is the classifier correct?\n",
    "$$\\frac{(TP+TN)}{total}$$\n",
    "\n",
    "\n",
    "- Misclassification Rate: Overall, how often is it wrong?\n",
    "$$\\frac{(FP+FN)}{total}$$ \n",
    "    equivalent to 1 minus Accuracy.\n",
    "    \n",
    "    also known as \"Error Rate\"\n",
    "    \n",
    "    \n",
    "- True Positive Rate: When it's actually yes, how often does it predict yes?\n",
    "$$\\frac{TP}{Actual Yes}$$ \n",
    "    also known as \"Sensitivity\" or \"Recall\"\n",
    "    \n",
    "    \n",
    "- False Positive Rate: When it's actually no, how often does it predict yes?\n",
    "$$\\frac{FP}{Actual No}$$ \n",
    "\n",
    "\n",
    "- True Negative Rate: When it's actually no, how often does it predict no?\n",
    "$$\\frac{TN}{Actual No}$$ \n",
    "    equivalent to 1 minus False Positive Rate\n",
    "    \n",
    "    also known as \"Specificity\"\n",
    "    \n",
    "    \n",
    "- Precision: When it predicts yes, how often is it correct?\n",
    "$$\\frac{TP}{Predicted Yes}$$ \n",
    "\n",
    " \n",
    "- Prevalence: How often does the yes condition actually occur in our sample?\n",
    "$$\\frac{Actual Yes}{Total}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate all the above metrics with the given example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Time\n",
    "1. Learn about F1-Score and ROC curve. \n",
    "2. Calculate the F1-Score for the above example. \n",
    "3. Learn how to code and plot the ROC curve.\n",
    "4. Plot the ROC curve for the above example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F1-Score:\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You already know how to calculate the accuracy. Find out how you can use scikit learn's functions to find precision, recall and F1-score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer\n",
    "# list the functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose the Best Classifier\n",
    "### Load the data\n",
    "Use your improved data (without PCA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to test and training set\n",
    "Set the random state value to 42. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN Classifier\n",
    "Copy your code from the previous notebooks to fit a KNN classifier to your data. Use a for loop to test different k values from 1 to 10 and use a plot showing the value of each metric corresponding to each k. Then save Accuracy, Precision, Recall, and F1 score of the best k in ``acc_knn``, ``p_knn``, ``r_knn``, and ``f1_knn`` using your defined functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree\n",
    "Read about Decision Trees (DT) [here](https://scikit-learn.org/stable/modules/tree.html). Then, write a piece of code to fit a DT classifier to your data and print Accuracy, Precision, Recall, and F1 score. \n",
    "\n",
    "#### Parameter Tuning\n",
    "Change maximum depth in your decision tree and observe its effect on the metrics. Try at least 10 different values and generate a plot showing the value of each metric corresponding to each depth.\n",
    "\n",
    "Save the scores of the best one in ``acc_dt``, ``p_dt``, ``r_dt``, and ``f1_dt``.\n",
    "\n",
    "Recall: we also learned about the decision trees in practice problems throughout the lectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifer\n",
    "Random Forest classifier is an ensemble of Decision Trees. The idea is that each Decision Tree will be a weak learner capturing part of the features in each class and the Random Forest will be a strong classifier when it combines all the weak learners. Copy your Random Forest algorithm you implemented the in previous sessions and report the metrics on your data.\n",
    "\n",
    "#### Paramter Tuning\n",
    "Change number of Decision Trees in your Random Forest Classifier and observe its effect on the metrics. Try at least 10 different values and generate a plot showing the value of each metric corresponding to number [soure](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html).\n",
    "\n",
    "Save the scores of the best one in ``acc_rf``, ``p_rf``, ``r_rf``, and ``f1_rf``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines\n",
    "Copy your SVM code from previous notbooks. SVM is one the strongest and most popular classifiers in the field of Data Science. Write a piece of code that fits an SVM classifier to your data.\n",
    "#### Parameter Tuning\n",
    "Retrain your SVM classifier with different kernels and save the metrics of the best one in ``acc_svm``, ``p_svm``,`` r_svm``, ``f1_svm``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the best model\n",
    "Generate 4 plots, each for comparing the classifiers based on one metirc. The x axis will be the models and the y axis will be the value of the corresponding parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the aforementioned steps for the data with PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plots to choose the best model\n",
    "# Your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Advanced Exercises (optional)**:\n",
    "- Use different test and train ratios (10/90, 20/80, 30/70)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"We are almost done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n",
    "- [Simple guide to confusion matrix terminology](https://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
